{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "411cbffa-4a9a-4b91-b74a-fd49acbf06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd #pandas class\n",
    "import numpy as np\n",
    "import traceback\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "import category_encoders as ce\n",
    "import time\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, accuracy_score, roc_curve\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import logging\n",
    "plt.style.use('_mpl-gallery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3de6bd3-5be3-4933-9fe6-6785e7fff1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure logger\n",
    "log_filename=f\"C:\\\\Custom\\\\Semester 2\\\\CA683 DADM\\\\Home Loan Approval System\\\\logs\\\\{(time.asctime()).replace(' ','_')}\"\n",
    "logging.basicConfig(filename=log_filename,filemode='a',format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4df6b84-01d2-40c1-a5c2-c6bb2866e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        \n",
    "        filepath=f\"C:\\\\Custom\\\\Semester 2\\\\CA683 DADM\\\\Home Loan Approval System\\\\Cleaning_3.csv\"\n",
    "        df=pd.read_csv(filepath)\n",
    "        df.drop(columns='Unnamed: 0',inplace=True)\n",
    "        #take backup of file\n",
    "        backup=copy.deepcopy(df)\n",
    "        \n",
    "except Exception as ex:\n",
    "    print(f'Following exception:\\n {ex}')\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e03042-d4d1-4e71-8075-a60262a3c0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 158)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcfb718e-1101-415a-a627-2c869ce6d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24825, 158)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for no of positive examples\n",
    "df[df.iloc[:,0]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43d0fb-df54-4cff-abc3-1a5a71dbbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Firstly, we'll select all the features and use few tree-based models.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7dc01e-868d-4f69-8354-ee2abcf0cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Separate target from predictors.'''\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdfac58-4ce2-48f1-91ac-4356e017f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data in train, cross validation\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb68b7e-cf88-4de8-85cf-dfb2f791f816",
   "metadata": {},
   "source": [
    "The basic XGBoost model with no hyperparamter tuning.\n",
    "\n",
    "The suitable evaluation metrics for this analysis is AUC score because of binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff5f0fb3-81af-475f-ab7a-5bbaf86ffbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(X_train,X_val,y_train,y_val):\n",
    "    '''XGBoost model to fit and score various'''\n",
    "    \n",
    "    #define model\n",
    "    xgboost = GradientBoostingClassifier(random_state=0).fit(X_train,y_train)\n",
    "        \n",
    "    #predict\n",
    "    y_predict = xgboost.predict(X_val)\n",
    "    \n",
    "    #compute metric\n",
    "    auc_score = roc_auc_score(y_val, y_predict)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_predict).ravel() \n",
    "    precision = precision_score(y_val, y_predict)\n",
    "    recall = recall_score(y_val, y_predict)\n",
    "    accuracy = accuracy_score(y_val, y_predict)\n",
    "    \n",
    "    #print results\n",
    "    print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ', fn, '\\nTrue Positives: ', tp)\n",
    "    print ('Precision: ', precision, '\\nRecall: ', recall)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('The AUC score is {}'.format(auc_score))\n",
    "    \n",
    "    return xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5af576f5-cd7c-4b87-8ca4-142996d3a8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  84763 \n",
      "False positives:  78 \n",
      "False negatives:  7322 \n",
      "True Positives:  91\n",
      "Precision:  0.5384615384615384 \n",
      "Recall:  0.012275731822474031\n",
      "Accuracy:  0.9197866759164914\n",
      "The AUC score is 0.5056781825034506\n"
     ]
    }
   ],
   "source": [
    "xgboost_default = xgboost_model(X_train,X_val,y_train,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab3bd5-8a2d-4f18-85e2-fce4ddacaab5",
   "metadata": {},
   "source": [
    "The default xgboost model is pretty bad with only 91 TP were identified even with 50% percent score.\n",
    "\n",
    "In order to not to limit ourselves to any one ensemble methods, we will run another model random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85422afd-aa94-46ac-95d3-2ce56e816f21",
   "metadata": {},
   "source": [
    "Default Random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df30a269-da62-4df3-837d-3de3b9d35d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Random Forest classifier.'''\n",
    "def randomforest_model(X_train,X_val,y_train,y_val):\n",
    "    '''Random forest model to fit and score various'''\n",
    "\n",
    "    #define default model\n",
    "    random_forest=RandomForestClassifier(random_state=0).fit(X_train,y_train)\n",
    "    \n",
    "    #predict\n",
    "    y_predict = random_forest.predict(X_val)\n",
    "    \n",
    "    #compute metric\n",
    "    auc_score = roc_auc_score(y_val,y_predict)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_predict).ravel() \n",
    "    precision = precision_score(y_val, y_predict)\n",
    "    recall = recall_score(y_val, y_predict)\n",
    "    accuracy = accuracy_score(y_val, y_predict)\n",
    "    \n",
    "    #print results\n",
    "    print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ', fn, '\\nTrue Positives: ', tp)\n",
    "    print ('Precision: ', precision, '\\nRecall: ', recall)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('The AUC score is {}'.format(auc_score))\n",
    "    \n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64a69051-c5dc-4ac2-b966-de2adcc74327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  84836 \n",
      "False positives:  5 \n",
      "False negatives:  7404 \n",
      "True Positives:  9\n",
      "Precision:  0.6428571428571429 \n",
      "Recall:  0.0012140833670578712\n",
      "Accuracy:  0.9196891191709845\n",
      "The AUC score is 0.5005775747984145\n"
     ]
    }
   ],
   "source": [
    "randomforest_default = randomforest_model(X_train,X_val,y_train,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261f64c-1157-44e8-9f56-ef5a621bb714",
   "metadata": {},
   "source": [
    "Random forest model is also not good in identifying the true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf388f48-a324-4169-a6bf-665ad86633b6",
   "metadata": {},
   "source": [
    "Before we perform hyperparameter tunning it appear our positive examples are very less. It might be a good idea to perform oversampling so that our model can learn the\n",
    "positive examples better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0ba5c3-b39f-4e3d-a8c4-fc193c12a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "\n",
    "#split the data first.\n",
    "X_train_over,X_val_over,y_train_over,y_val_over = train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "\n",
    "#fit and apply the transform\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8e43f30-7f19-4cf1-99b3-1afe1d4b9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  84731 \n",
      "False positives:  110 \n",
      "False negatives:  7302 \n",
      "True Positives:  111\n",
      "Precision:  0.502262443438914 \n",
      "Recall:  0.014973694860380412\n",
      "Accuracy:  0.9196566002558154\n",
      "The AUC score is 0.5068385759576711\n"
     ]
    }
   ],
   "source": [
    "#random forest with oversampling\n",
    "randomforest_default_over = randomforest_model(X_train_over,X_val_over,y_train_over,y_val_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcd9554b-716f-469c-818a-98664352b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  58490 \n",
      "False positives:  26351 \n",
      "False negatives:  2418 \n",
      "True Positives:  4995\n",
      "Precision:  0.15935047533975627 \n",
      "Recall:  0.6738162687171185\n",
      "Accuracy:  0.688154443167776\n",
      "The AUC score is 0.6816117564280775\n"
     ]
    }
   ],
   "source": [
    "#XGBoost with oversampled dataset.\n",
    "xgboost_default_over = xgboost_model(X_train_over,X_val_over,y_train_over,y_val_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc888680-5445-48a0-8588-bc98b9752533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost with oversampling increased our model's AUC score to 0.69."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c31fd-d7d3-4782-9ba9-be20e91c066c",
   "metadata": {},
   "source": [
    "Clearly, oversampling our dataset is performing really well, even without any hyperparameter tunning.\n",
    "\n",
    "The default XGBoost with oversample gave us any output of 0.69 AUC score, whereas the Random Forest performed with 0.50 AUC score. The number of true positives are increased significantly.\n",
    "\n",
    "Fine-tuning XGBoost classifier with oversampled dataset might give us a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c498a-2ede-42cf-bd19-24f65f1a5605",
   "metadata": {},
   "source": [
    "Let's set the max depth between 2 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a53985-e2f8-4998-ba12-86b157d1a70d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def xgboost_model_tune(X_train, X_val, y_train, y_val):\n",
    "    '''XGBoost model to fit with hyperparameter tunning and score various metrics.'''\n",
    "    \n",
    "    #max_depth = [5,7,10] #Increasing the depth, decreases the AUC score, check the logs.\n",
    "    #learning_rate = [0.5, 1.0]  #[0.001, 0.01, 0.25]\n",
    "    #estimators = [10, 25, 50, 125, 200]\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        \n",
    "        logging.info('Training with estimator: {}'.format(estimator))\n",
    "        \n",
    "        #define model\n",
    "        xgboost = GradientBoostingClassifier(n_estimators = estimator, random_state = 0,)\\\n",
    "        .fit(X_train, y_train)\n",
    "        \n",
    "        #predict\n",
    "        y_predict = xgboost.predict(X_val)\n",
    "    \n",
    "        #compute metric\n",
    "        auc_score = roc_auc_score(y_val, y_predict)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_predict).ravel() \n",
    "        precision = precision_score(y_val, y_predict)\n",
    "        recall = recall_score(y_val, y_predict)\n",
    "        accuracy = accuracy_score(y_val, y_predict)\n",
    "    \n",
    "        #print results\n",
    "        logging.info(f'True negatives: {tn}, \\nFalse positives: {fp}, \\nFalse negatives: {fn}, \\nTrue Positives: {tp}')\n",
    "        logging.info(f'Precision: {precision}, \\nRecall:  {recall}')\n",
    "        logging.info(f'Accuracy: {accuracy}')\n",
    "        logging.info(f'The AUC score is {auc_score}')\n",
    "    \n",
    "    return xgboost\n",
    "\n",
    "xgboost_tune = xgboost_model_tune(X_train_over, X_val, y_train_over, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f4d58-fd9f-4cfb-8fd5-9765cd5fd663",
   "metadata": {},
   "source": [
    "Manual hyperparamter tuning didn't improve the result much.\n",
    "\n",
    "So, now the question is out of 157 predictors how many are important to train our model and what are irrelavant.\n",
    "We'll try to check the feature importance in our model to identify the best subset of predictors to achieve global optimum.\n",
    "\n",
    "For this we'll use a greedy feature selection approach called RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "785b3377-e7e4-4ce9-aa4d-e77a3cb6038a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''XGBoost with recursive feature elimination.\n",
    "'''\n",
    "def compute_metrics(model,X_train,y_train,X_val,y_val):\n",
    "    '''Function to compute test and validation accuracy'''\n",
    "    \n",
    "    logging.info('Execution start compute_metrics')\n",
    "    \n",
    "    f_score = 0 \n",
    "    \n",
    "    #calculate accuracy\n",
    "    train_accuracy_score = model.score(X_train,y_train)\n",
    "    val_accuracy_score = model.score(X_val,y_val)\n",
    "    logging.info('Train accuracy achieved is {}'.format(train_accuracy_score))\n",
    "    logging.info('Validation accuracy achieved is {}'.format(val_accuracy_score))\n",
    "    \n",
    "    #calculate TP, TN, FP, FN\n",
    "    prediction = model.predict(X_val)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, prediction).ravel()\n",
    "    logging.info(f'True negatives: {tn}, False positives: {fp}, False negatives: {fn}, True Positives: {tp}')\n",
    "    \n",
    "    #calculate f1_score\n",
    "    f_score = f1_score(y_val,prediction)\n",
    "    logging.info('F1 Score: {}'.format(f_score))\n",
    "    \n",
    "    logging.info('Execution end compute_metrics')\n",
    "    \n",
    "    #calculate auc_score\n",
    "    auc_score = roc_auc_score(y_val,prediction)\n",
    "    logging.info('AUC score: {}'.format(auc_score))\n",
    "    \n",
    "    return auc_score\n",
    "    \n",
    "def compute_permutation_importance(model,X_val,y_val):\n",
    "    '''Calculate permuation importance of model's predictors.\n",
    "        Reason for choosing this method is because the predictors are of various data types.\n",
    "    '''\n",
    "    \n",
    "    logging.info('Execution start compute_permutation_importance function')\n",
    "    \n",
    "    #train_result = permutation_importance(model,X_train,y_train,n_repeats=5,n_jobs=2,random_state=42)\n",
    "    val_result = permutation_importance(model,X_val,y_val,n_repeats=5,n_jobs=2,random_state=42)\n",
    "    \n",
    "    sorted_idx = val_result.importances_mean.argsort()\n",
    "    \n",
    "    #train_importances = pd.DataFrame(train_result.imp[sorted_idx].T,columns=X_train.column[sorted_idx])\n",
    "    test_importances = pd.DataFrame(val_result.importances[sorted_idx].T,columns=X_val.columns[sorted_idx])\n",
    "    \n",
    "    logging.info('Execution end compute_permutation_importance function.')\n",
    "    \n",
    "    return test_importances\n",
    "\n",
    "def recursive_feature_selection(X_over,y_over):\n",
    "    '''The function will employ a feature selection technique names RFE to identify minimun subset of features that can achieve\n",
    "        our objective and make prediction with acceptable accuracy.\n",
    "    '''\n",
    "    \n",
    "    logging.info('Execution start recursive_feature_selection function.')\n",
    "    \n",
    "    #declare variables\n",
    "    assessment_sheet = {}\n",
    "    sampling_count = 10\n",
    "    rfe_df = copy.deepcopy(df)\n",
    "    \n",
    "    logging.info(f'Initial dataframe predictors shape: {X_over.shape}, and response shape: {y_over.shape}')\n",
    "\n",
    "    while sampling_count > 0:\n",
    "        \n",
    "        auc_score = 0\n",
    "        logging.info('-'*180)\n",
    "        \n",
    "        #assign predictors and response to X, y for simplicity\n",
    "        X = X_over.sample(frac = 0.5, random_state = 42, axis = 1)\n",
    "        y =  y_over\n",
    "        logging.info(f'Predictors shape: {X.shape}, Response shape: {y.shape}')\n",
    "    \n",
    "        #Split the data in train, cross validation.\n",
    "        X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "                    \n",
    "        num_of_predictors = X_train.shape[1]\n",
    "        \n",
    "        while num_of_predictors > 25:\n",
    "            \n",
    "            #define default model\n",
    "            xgboost = GradientBoostingClassifier().fit(X_train,y_train)\n",
    "    \n",
    "            #compute evaluation metrics\n",
    "            auc_score = compute_metrics(xgboost,X_train,y_train,X_val,y_val)\n",
    "        \n",
    "            #print the auc score with current subset of predictors.\n",
    "            logging.info('Current subset of predictors are: {}'.format(list(X.columns)))\n",
    "        \n",
    "            #compute permuation importance\n",
    "            test_importances = compute_permutation_importance(xgboost,X_val,y_val)\n",
    "    \n",
    "            #identify the least importance feature\n",
    "            lst_imp=np.mean(test_importances,axis=0).sort_values().head(1)\n",
    "            lst_imp_index,lst_imp_value = list(lst_imp.index)[0],lst_imp.iloc[0]\n",
    "            logging.info(f'The least important predictor found in this iteration is: {lst_imp_index}, Value: {lst_imp_value}')  \n",
    "    \n",
    "            #remove the least important predictor\n",
    "            X_train.drop(columns = lst_imp_index, inplace = True)\n",
    "            X_val.drop(columns = lst_imp_index, inplace = True)\n",
    "            logging.info(f'Dropped the least important predictor from this iteration.')\n",
    "            logging.info(f'Current shape of predictors: {X_train.shape}')\n",
    "        \n",
    "            #assign remaining num of predictors.\n",
    "            num_of_predictors = X.shape[1]\n",
    "        \n",
    "        sampling_count -= 1\n",
    "    \n",
    "    logging.info('Execution end recursive_feature_selection function.')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3210bf8-9c4a-4ae7-b946-c86c912f3d4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pp/nbz4wc1x0t107w3zyv72bd080000gn/T/ipykernel_3049/3214567065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecursive_feature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_over\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pp/nbz4wc1x0t107w3zyv72bd080000gn/T/ipykernel_3049/2508376191.py\u001b[0m in \u001b[0;36mrecursive_feature_selection\u001b[0;34m(X_over, y_over)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m#compute evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#print the auc score with current subset of predictors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pp/nbz4wc1x0t107w3zyv72bd080000gn/T/ipykernel_3049/2508376191.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(model, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_accuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mval_accuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy achieved is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation accuracy achieved is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \"\"\"\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         )\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_raw_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;34m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recursive_feature_selection(X_train_over,y_train_over)\n",
    "print('Process end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d5f250b-f596-4848-90c6-8da460168ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a577e5a-4b9a-400d-acea-cdfa6326116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [xgboost_default, randomforest_default, randomforest_default_over, xgboost_default_over]\n",
    "\n",
    "def plot_static_roc_curve(models):\n",
    "    '''Plot ROC curve of all the models provided in the list.'''\n",
    "    \n",
    "    #plt.figure(figsize = [18,18])\n",
    "    \n",
    "    fig, axs = plt.subplots(2,2, figsize = (5,5))\n",
    "    #fig.suptitle(\"ROC Curve\", va= 'center', ha = 'center')\n",
    "    \n",
    "    #plot 1\n",
    "    y_predict = models[0].predict(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val,  y_predict)\n",
    "    auc = roc_auc_score(y_val, y_predict)\n",
    "    \n",
    "    axs[0,0].fill_between(fpr, tpr, alpha=.5)\n",
    "    axs[0,0].plot(fpr, tpr,label=\"data 1, auc=\"+str(auc), linestyle=(0, (5, 5)), linewidth=2)\n",
    "    axs[0,0].set_title('XGBoost without oversampling', color = 'r')\n",
    "    \n",
    "    #plot 2\n",
    "    y_predict = models[1].predict(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val,  y_predict)\n",
    "    auc = roc_auc_score(y_val, y_predict)\n",
    "    \n",
    "    axs[0,1].fill_between(fpr, tpr, alpha=.5)\n",
    "    axs[0,1].plot(fpr, tpr,label=\"data 1, auc=\"+str(auc), linestyle=(0, (5, 5)), linewidth=2)\n",
    "    axs[0,1].set_title('RF without oversampling', color = 'r')\n",
    "\n",
    "    \n",
    "    #plot 4\n",
    "    y_predict = models[2].predict(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val,  y_predict)\n",
    "    auc = roc_auc_score(y_val, y_predict)\n",
    "    \n",
    "    axs[1,1].fill_between(fpr, tpr, alpha=.5)\n",
    "    axs[1,1].plot(fpr, tpr,label=\"data 1, auc=\"+str(auc), linestyle=(0, (5, 5)), linewidth=2)\n",
    "    axs[1,1].set_title('XGBoost with oversampling', color = 'r')\n",
    "    \n",
    "    \n",
    "    #plot 3\n",
    "    y_predict = models[3].predict(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val,  y_predict)\n",
    "    auc = roc_auc_score(y_val, y_predict)\n",
    "    \n",
    "    axs[1,0].fill_between(fpr, tpr, alpha=.5)\n",
    "    axs[1,0].plot(fpr, tpr,label=\"data 1, auc=\"+str(auc), linestyle=(0, (5, 5)), linewidth=2)\n",
    "    axs[1,0].set_title('RF with oversampling', color = 'r')\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "        \n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    plt.show()\n",
    "    \n",
    "plot_static_roc_curve(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff9c9d-89fb-43b0-857e-5ef09861e779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
